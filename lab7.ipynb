{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c01d229-b690-4d43-9356-b3e03026e0d7",
   "metadata": {},
   "source": [
    "## ðŸ”§ 1. Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6fc617-0580-40e4-a132-84a4aa81fba6",
   "metadata": {},
   "source": [
    "You can install PySpark via pip:\n",
    "```\n",
    "pip install pyspark\n",
    "```\n",
    "To verify the installation, run the following command in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4045cab8-f55b-4a00-8728-e54fef9c99d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.4\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "print(pyspark.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873eef98-5769-466a-81f0-ce35a7eada6b",
   "metadata": {},
   "source": [
    "Before intializing PySpark, please make sure your computer installed Java 8 or later, but Java 9+ can sometimes cause issues. To check your Java version, run:\n",
    "```{sh}\n",
    "java -version\n",
    "```\n",
    "You should see something like:\n",
    "```\n",
    "java version \"1.8.0_281\"\n",
    "```\n",
    "If Java is not installed, install it trough the link\n",
    "-  MacBook: [Install Java on MacBook](https://www.java.com/en/download/) (Check if your computer has Intel or Apple M CPU first)\n",
    "-  Windows: [Install Java on PC](https://www.java.com/download/ie_manual.jsp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4bb245-6e8a-4990-9472-ecfcf9ae9bbf",
   "metadata": {},
   "source": [
    "## ðŸš€ 2. Start a Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7acef92e-5093-4859-9ca5-c91af793a9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/05/18 23:15:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"PySpark_Tutorial\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40ef85b-ad74-4d48-a7c6-6d4c0bb3a77f",
   "metadata": {},
   "source": [
    "## ðŸ“‚ 3. Load and Explore Data\n",
    "The data required for this example is saved at s3://de300spring2025/dinglin_xia/data/adult.csv.\n",
    "\n",
    "Assuming your file is named \"adult.csv\" and contains a column \"filtered\" (JSON array of words):\n",
    "Weâ€™ll walk through several important steps:\n",
    "\n",
    "1. Feature Engineering\n",
    "\n",
    "2. Bias Analysis on Marital Status\n",
    "\n",
    "3. Joining with Supplemental Gender Data\n",
    "\n",
    "4. Exporting Final Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbe3712-567a-46be-84cc-66dccc795810",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, FloatType\n",
    "from pyspark.sql.dataframe import DataFrame\n",
    "from pyspark.sql.functions import col, when, isnan, isnull, count, avg, trim\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0feb1a8-a60d-4b3f-9c1c-4b9dcbf8c1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = \"data\"\n",
    "# source https://www.statista.com/statistics/242030/marital-status-of-the-us-population-by-sex/\n",
    "# the first value is male and the second is for female\n",
    "MARITAL_STATUS_BY_GENDER = [\n",
    "    [\"Never-married\", 47.35, 41.81],\n",
    "    [\"Married-AF-spouse\", 67.54, 68.33],\n",
    "    [\"Widowed\", 3.58, 11.61],\n",
    "    [\"Divorced\", 10.82, 15.09]\n",
    "]\n",
    "MARITAL_STATUS_BY_GENDER_COLUMNS = [\"marital_status_statistics\", \"male\", \"female\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001d819f-2cc6-4342-b7a8-ee3fe21565c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(spark: SparkSession) -> DataFrame:\n",
    "    \"\"\"\n",
    "    read data based on the given schema; this is much faster than spark determining the schema\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the schema for the dataset\n",
    "    schema = StructType([\n",
    "        StructField(\"age\", IntegerType(), True),\n",
    "        StructField(\"workclass\", StringType(), True),\n",
    "        StructField(\"fnlwgt\", FloatType(), True),\n",
    "        StructField(\"education\", StringType(), True),\n",
    "        StructField(\"education_num\", FloatType(), True),\n",
    "        StructField(\"marital_status\", StringType(), True),\n",
    "        StructField(\"occupation\", StringType(), True),\n",
    "        StructField(\"relationship\", StringType(), True),\n",
    "        StructField(\"race\", StringType(), True),\n",
    "        StructField(\"sex\", StringType(), True),\n",
    "        StructField(\"capital_gain\", FloatType(), True),\n",
    "        StructField(\"capital_loss\", FloatType(), True),\n",
    "        StructField(\"hours_per_week\", FloatType(), True),\n",
    "        StructField(\"native_country\", StringType(), True),\n",
    "        StructField(\"income\", StringType(), True)\n",
    "    ])\n",
    "\n",
    "    # Read the dataset\n",
    "    data = spark.read \\\n",
    "        .schema(schema) \\\n",
    "        .option(\"header\", \"false\") \\\n",
    "        .option(\"inferSchema\", \"false\") \\\n",
    "        .csv(os.path.join(DATA_FOLDER,\"*.csv\")) \n",
    "\n",
    "    data = data.repartition(8)\n",
    "\n",
    "    float_columns = [f.name for f in data.schema.fields if isinstance(f.dataType, FloatType)]\n",
    "    for v in float_columns:\n",
    "        data = data.withColumn(v, data[v].cast(IntegerType()))\n",
    "\n",
    "    # Get the names of all StringType columns\n",
    "    string_columns = [f.name for f in data.schema.fields if isinstance(f.dataType, StringType)]\n",
    "\n",
    "    # Remove leading and trailing spaces in all string columns\n",
    "    for column in string_columns:\n",
    "        data = data.withColumn(column, trim(data[column]))\n",
    "\n",
    "    # Show the first 5 rows of the dataset\n",
    "    data.show(5)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00d1148-ba19-4e77-9e11-9d78b0af2124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_values(data: DataFrame) -> DataFrame:\n",
    "    \"\"\"\n",
    "    count the number of samples with missing values for each row\n",
    "    remove such samples\n",
    "    \"\"\"\n",
    "\n",
    "    missing_values = data.select([count(when(isnan(c) | isnull(c), c)).alias(c) for c in data.columns])\n",
    "\n",
    "    # Show the missing values count per column\n",
    "    missing_values.show()\n",
    "\n",
    "    # Get the number of samples in the DataFrame\n",
    "    num_samples = data.count()\n",
    "\n",
    "    # Print the number of samples\n",
    "    print(\"Number of samples:\", num_samples)  \n",
    "\n",
    "    data = data.dropna()      \n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e17741-06c7-47a6-b399-e7457604feda",
   "metadata": {},
   "source": [
    "### ðŸ“Œ Feature Engineering Function\n",
    "ðŸ“– Explanation:\n",
    "This function programmatically finds all integer features and creates new features by multiplying each pair. It helps capture interaction effects for models or exploratory analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2cf776-3fd6-45a7-8420-b4a34f280c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(data: DataFrame) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate the product of each pair of integer features\n",
    "    \"\"\"\n",
    "    # Identify all integer-type columns in the dataset\n",
    "    integer_columns = [f.name for f in data.schema.fields if isinstance(f.dataType, IntegerType)]\n",
    "    \n",
    "    # For each pair of integer columns, compute a new column that is their product\n",
    "    for i, col1 in enumerate(integer_columns):\n",
    "        for col2 in integer_columns[i:]:  # Avoid duplicate pairs\n",
    "            product_col_name = f\"{col1}_x_{col2}\"\n",
    "            data = data.withColumn(product_col_name, col(col1) * col(col2))\n",
    "    \n",
    "    # Preview first 5 rows to check new columns\n",
    "    data.show(5)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126bc286-d8a4-43c8-9622-f77f130de689",
   "metadata": {},
   "source": [
    "### ðŸ“Œ Analyze Bias by Marital Status\n",
    "ðŸ“– Explanation:\n",
    "This function investigates if capital_gain varies significantly with marital_status. It also filters and inspects a specific subgroup â€” divorced individuals â€” to facilitate further analysis or visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7fe919-a492-4ab1-b81a-8ed349da2922",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bias_marital_status(data: DataFrame):\n",
    "    \"\"\"\n",
    "    Analyze if there's a bias in capital gain by marital status\n",
    "    \"\"\"\n",
    "    # Group by marital status and compute average capital gain\n",
    "    average_capital_gain = data.groupBy(\"marital_status\").agg(avg(\"capital_gain\").alias(\"average_capital_gain\"))\n",
    "    average_capital_gain.show()\n",
    "\n",
    "    # Filter only rows with marital_status == \"Divorced\"\n",
    "    divorced_data = data.filter(data.marital_status == \"Divorced\")\n",
    "    divorced_data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1903cc2d-0257-47f1-98be-30d4a7efd81c",
   "metadata": {},
   "source": [
    "### ðŸ“Œ Join with External Gender Statistics\n",
    "ðŸ“– Explanation:\n",
    "This function enriches the dataset by joining it with an external dataset containing U.S. gender distribution by marital status. The `outer` join ensures we keep unmatched records for completeness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d546c6-97a3-48da-99ce-4fa7bab4e468",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_with_US_gender(spark: SparkSession, data: DataFrame):\n",
    "    \"\"\"\n",
    "    Join with external data about marital status statistics by gender\n",
    "    \"\"\"\n",
    "    # Example data (assumed predefined in MARITAL_STATUS_BY_GENDER & *_COLUMNS)\n",
    "    us_df = spark.createDataFrame(MARITAL_STATUS_BY_GENDER, MARITAL_STATUS_BY_GENDER_COLUMNS)\n",
    "\n",
    "    # Outer join on marital_status\n",
    "    return data.join(us_df, data.marital_status == us_df.marital_status_statistics, 'outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2822d331-8057-430a-88e7-0e8a0fbddd9b",
   "metadata": {},
   "source": [
    "### âœ… Main Pipeline\n",
    "ðŸ“– Explanation:\n",
    "This function ties all preprocessing steps together and writes the result to a CSV file. You can run it with main() in a PySpark environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb5e52c-cece-495e-9644-87a2de0a8b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    spark = SparkSession.builder.appName(\"Read Adult Dataset\").getOrCreate()\n",
    "    \n",
    "    data = read_data(spark)               # Load dataset\n",
    "    data = missing_values(data)           # Handle missing values (assumed implemented)\n",
    "    data = feature_engineering(data)      # Add interaction features\n",
    "    bias_marital_status(data)             # Analyze capital gain by marital status\n",
    "    data = join_with_US_gender(spark, data)  # Enrich with gender statistics\n",
    "    \n",
    "    data.show(5)                          # Preview final data\n",
    "    data.write.format('csv').option('header', 'true').mode('overwrite').save('saved.csv')  # Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa374bbe-e287-4e36-b9ee-758deeec36a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39619e2-5dfa-4671-9ffc-0ce9b8b8c90e",
   "metadata": {},
   "source": [
    "## Lab Assignment\n",
    "### Word Count\n",
    "1 Save only the words that have count greater or equal to 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670d34cc-1161-48b9-8591-62b9ca1c3598",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
