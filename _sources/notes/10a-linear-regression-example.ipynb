{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41b55f4f-29bc-49fc-aa47-0025b9452381",
   "metadata": {},
   "source": [
    "# (EX) PySpark example with linear regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a56216-446e-4dcb-9869-8127ce1b77b2",
   "metadata": {},
   "source": [
    "This set of notes covers the estimation and prediction with a linear regression model, and the use of PySpark in order to parallelize and scale in computation.  In addition, the notes provide a brief commentary on privacy preserving machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e1696f-62d0-4e46-a618-1a379981694a",
   "metadata": {},
   "source": [
    "## Linear regression refresher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d763ec6-36d8-46b5-8345-3b9a742d772b",
   "metadata": {},
   "source": [
    "To fit a linear regression (without any penalty or regularization) can be done via the least-squares estimation:\n",
    "\n",
    "$$\\min_\\beta~\\ell(\\beta) = \\|\\mathbf{y} - \\mathbf{X} \\beta \\|_2^2,$$\n",
    "\n",
    "The corresponding analytical solution can be found by setting the partial derivatives to zero:\n",
    "$$\\frac{\\partial \\ell(\\beta)}{\\partial \\beta} \\equiv 0 \\qquad \\Rightarrow \\qquad \\widehat{\\beta} = (\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1} \\mathbf{X}^\\mathsf{T}\\mathbf{y}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e15cb1-53b0-4b36-8ec5-81ea0531cd4d",
   "metadata": {},
   "source": [
    "*Why do we need to think about parallelization at all?*\n",
    "\n",
    "Say we have $n$ data points, i.e. $(\\mathbf{x}_i, y_i)_{i=1}^n$. Take a look at the dimension of the quantities of interest:\n",
    "$$\\mathbf{X} \\in \\mathbb{R}^{n \\times (d+1)}, \\mathbf{y} \\in \\mathbb{R}^n.$$\n",
    "\n",
    "The major computations involve three operations:  \n",
    "1. Multiplication: $\\mathbf{X}^\\mathsf{T}\\mathbf{X} = \\sum_{i=1}^n \\mathbf{x}_i \\mathbf{x}_i^\\mathsf{T},$\n",
    "2. Multiplication: $\\mathbf{X}^\\mathsf{T}\\mathbf{y} = \\sum_{i=1}^n \\mathbf{x_i} y_i,$\n",
    "3. Inversion of matrix: $(\\mathbf{X}^\\mathsf{T}\\mathbf{X})^{-1} \\mathbf{X}^\\mathsf{T}\\mathbf{y}.$\n",
    "\n",
    "*Rationale:*  \n",
    "- In the case where $n$ is extremely large, the multiplication and summation, steps (1) and (2), are slow.\n",
    "- Since the inversion of matrix is driven by the size of $\\mathbf{X}^\\mathsf{T}\\mathbf{X}$, which is typically a relatively small $(d+1) \\times (d+1)$ matrix.  Step (3) is relatively cheap in terms of computation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5eb6672-4713-4c8b-9f82-c813832c5fdb",
   "metadata": {},
   "source": [
    "## Coding component with the diamonds dataset as an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a389d933-9a4c-4854-8a11-67ee39d69bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You typically do not need this\n",
    "\n",
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = r\"C:\\Program Files\\Java\\jdk-11.0.2\"\n",
    "os.environ[\"SPARK_HOME\"] = r\"C:\\Program Files\\Spark\\spark-3.5.5-bin-hadoop3\"\n",
    "\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7950b3f8-1701-436b-a878-a9f639daa8c5",
   "metadata": {},
   "source": [
    "### Diamonds dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da7ade4-e0fb-42b9-89f6-8d6f05f820c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "diam = sns.load_dataset('diamonds', cache=True, data_home='dataset/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff62155-c708-4250-8e54-af55450f2465",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "# reading data\n",
    "diamonds = (\n",
    "    spark.read.format('csv')\n",
    "    .options(header='true', inferSchema='true')\n",
    "    .load('dataset/diamonds.csv')\n",
    "    .cache()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a1d121-65a0-457d-a880-fbde46bfba31",
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16f7655-e8a4-40bc-9837-b3eecb62f428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsetting dataset for analysis\n",
    "df = (\n",
    "    diamonds\n",
    "    .where(diamonds['price'] > 1000)\n",
    "    .select(['cut', 'color', 'carat', 'clarity', 'price'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09688903-93a9-415b-8fd8-a004e8a0420a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccae6668-ac81-45ef-abbd-7c2be820a198",
   "metadata": {},
   "outputs": [],
   "source": [
    "row = diamonds.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab35160-74f4-44ed-82e0-e79846589d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigning predictors and response\n",
    "predictors = ['cut', 'color', 'carat', 'clarity']\n",
    "categorical = set(['cut', 'color', 'clarity'])\n",
    "response = 'price'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491b5f26-b978-43a8-b8c7-88fd2892ec17",
   "metadata": {},
   "source": [
    "### Map functions explained - collecting necessary information\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7720415-ea74-4286-939c-542e1564c041",
   "metadata": {},
   "source": [
    "The individual (row) component within the sum can be calculated as:\n",
    "\n",
    "\\begin{align}\n",
    "    \\mathbf{x}_i \\mathbf{x}_i^\\mathsf{T} = \n",
    "    \\begin{pmatrix} \n",
    "    x_{i1}^2 & x_{i1} x_{i2} & \\ldots & x_{i1} x_{id} \\\\\n",
    "    \\vdots & \\ddots & \\ldots & \\vdots \\\\\n",
    "    x_{id}x_{i1} & x_{id}x_{i2} & \\ldots & x_{id}^2 \n",
    "    \\end{pmatrix},\n",
    "    \\qquad \n",
    "    \\mathbf{x}_i y_i = \n",
    "    \\begin{pmatrix} \n",
    "    x_{i1}y_i \\\\ x_{i2} y_i \\\\ \\vdots \\\\ x_{id} y_i\n",
    "    \\end{pmatrix}.\n",
    "\\end{align}\n",
    "\n",
    "To keep track of which value corresponds to each column, the `yield` function keeps a record of the column names as keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd67173d-d42c-49aa-a25a-26db92b51284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map functions for step (1) and (2)\n",
    "def xtx_map(row):\n",
    "    row = row.asDict()\n",
    "    for i in predictors:\n",
    "        (ki, vi) = (i, row[i]) if i not in categorical else (i+\"_\"+row[i], 1.0)\n",
    "        for j in predictors:\n",
    "            (kj, vj) = (j, row[j]) if j not in categorical else (j+\"_\"+row[j], 1.0)\n",
    "            yield ((ki, kj), vi * vj)\n",
    "\n",
    "def xty_map(row):\n",
    "    row = row.asDict()\n",
    "    for j in predictors:\n",
    "        (kj, vj) = (j, row[j]) if j not in categorical else (j+\"_\"+row[j], 1.0)\n",
    "        yield (kj, vj * row[response])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45274c6-0aff-4898-92be-8f06579f7fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "row = df.take(1)\n",
    "row[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e4d868-2797-4c46-bdba-34c8b419fd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspecting the result from applying xty_map to one row\n",
    "[a for a in xty_map(row[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1054e3c4-48dc-4345-9044-b245fd9840c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspecting the result from applying xtx_map to one row\n",
    "[a for a in xtx_map(row[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39302f6d-24ff-4308-9700-7ea970673faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtx_data = (df.rdd\n",
    "            .flatMap(xtx_map)\n",
    "            .reduceByKey(lambda a, b: a+b)\n",
    "            .collect()\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce5ba18-697e-4738-affb-4b03fadd65af",
   "metadata": {},
   "outputs": [],
   "source": [
    "xty_data = (df.rdd\n",
    "            .flatMap(xty_map)\n",
    "            .reduceByKey(lambda a, b: a+b)\n",
    "            .collect()\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddcf8de-939e-4a5e-b920-5a14e08d48ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "xty_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d111f17-72aa-4e38-bba0-90f66928f5b1",
   "metadata": {},
   "source": [
    "### Indexing - keeping track of which columns the values belong to\n",
    "\n",
    "Individual calculations from distributed resources will return in **any** order, therefore, calculating the index of each column key is necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514dc582-af42-41ce-bada-4a89cafbe392",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = dict(zip([r[0] for r in xty_data], range(len(xty_data))))\n",
    "p = len(index)\n",
    "\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37585267-15fd-4de7-8186-52a6fe78f3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arrange the individual elements back into matrices\n",
    "import numpy as np\n",
    "\n",
    "XTY = np.zeros((p, 1))\n",
    "for (k, v) in xty_data:\n",
    "  XTY[index[k]] = v\n",
    "\n",
    "XTX = np.zeros((p,p))\n",
    "for ((k1,k2),v) in xtx_data:\n",
    "  XTX[index[k1], index[k2]] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d284f87-244c-4f83-94c0-1d785f8cddad",
   "metadata": {},
   "outputs": [],
   "source": [
    "XTX.shape, XTY.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6800e1be-9061-49bf-962a-e6f50c1835f2",
   "metadata": {},
   "source": [
    "### Estimation of $\\beta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0763f4d9-bd6b-41ab-bf46-4a0e56143074",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = np.linalg.solve(XTX, XTY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ead1d6a-d329-4f6d-883e-359225feabdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta  # beta hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a658b55d-40e2-49c0-9050-e670afdab6f6",
   "metadata": {},
   "source": [
    "## Prediction with $\\widehat{\\beta}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eaa8d17-4bbb-4e73-af0e-ec04547a0040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# digression: some handy shape-conforming functions in numpy\n",
    "beta.shape\n",
    "np.squeeze(beta).shape\n",
    "np.atleast_3d(beta).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40d8808-f206-4465-b799-eef02afaba92",
   "metadata": {},
   "outputs": [],
   "source": [
    "## a new row contains a set of predictors\n",
    "def predict(row):\n",
    "    row = row.asDict()\n",
    "    pred = 0.0\n",
    "    for j in predictors:\n",
    "        (kj, vj) = (j, row[j]) if j not in categorical else (j+\"_\"+row[j], 1.0)\n",
    "        pred += vj * beta[index[kj], 0]\n",
    "    return float(pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa84e5e4-3a34-4163-b13f-1d81f3eba2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import mean\n",
    "\n",
    "# calculating error\n",
    "rmse = np.sqrt(\n",
    "    df.rdd\n",
    "    .map(lambda row: (row[response], predict(row)))\n",
    "    .map(lambda y: (y[1] - y[0])**2)\n",
    "    .mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4555c4ea-589a-4534-a09d-7cdc04be0b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(\n",
    "    df.rdd\n",
    "    .map(lambda row: (row[response] - predict(row))**2)\n",
    "    .mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c02d9f-8fd1-4db2-a086-438e492e7ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038966e7-7914-44a2-a26b-02bccd14db5e",
   "metadata": {},
   "source": [
    "## User-defined functions (UDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66676f9f-0590-478d-b0c3-6fac10828a39",
   "metadata": {},
   "source": [
    "In many scenarios, storing the calculations in a new column of the RDD dataframe is advantageous. In a similar way, the computations are not performed until you try to retrieve the results, e.g. via \"collect\". \n",
    "\n",
    "User-defined functions allow for a clean way to achieve this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c13e20-7d30-4e0d-a423-18c4554bf15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf, struct\n",
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "predict_udf = udf(predict, FloatType())\n",
    "\n",
    "df = df.withColumn(\"pred\", predict_udf(struct(predictors)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275b95f8-ee2a-436a-938f-48e8fb0da502",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"resid\", df['pred'] - df['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ce879a-7640-4e78-8e8d-817e26bacefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51d4f18-2b8d-4ef0-819e-4ac0c34591f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df.sample(False, 0.1).select('resid').toPandas())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
