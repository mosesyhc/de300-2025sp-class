{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87ad3821-a522-4173-adbd-f7b4ee3dedcf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Distributed (cloud) computing\n",
    "\n",
    "This document covers the key elements for modern distributed computing, specifically a word on Hadoop and Spark."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a2dd49-7a0c-4e24-8af2-02bd3687a46e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Separation of compute from storage\n",
    "Traditionally compute and storage are colocated, e.g.,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd154c6-3b04-43de-aeb4-113f73700a7e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "- a transactional database leverages its low-latency disk reads and high bandwidth.\n",
    "- even for distributed jobs, a *map* job locates the location of data and runs the *map* local to the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c798a4-b02b-49ae-a613-8fb774d3e5ca",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Then why separate compute and storage?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2627d683-f1c7-4431-bc51-85ad25fff3db",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "- Availability of cloud computing and storage purchase\n",
    "  - Cost: It is cheap to buy and host a server than to rent *if the server is up 24/7*, minus *maintenance cost*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91321be-3bfe-42b2-a439-78d1af13a48f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "  - Towards ephermerality: (what we have done so far) Spin up an instance, use, and stop when done."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41a9ee6-f708-461e-8dfb-cce817e852eb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "  - Towards scalability: If you only need to run this titan job once a month, only pay for the resources then."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1c2213-5ac9-47a6-885a-269465a9beb4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "- Data durability and availability\n",
    "  - Fault tolerance: Replication of data increases availability and mitgates a write operation that destroys data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0fd53f-ef98-4e5e-9acc-0e554eae0bf4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Hybridization of separation and colocation\n",
    "In reality, compute and storage are not either separated or colocated, e.g., "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5ca559-6b56-4bb5-b4f3-522c564dcc66",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "- AWS elastic mapreduce (EMR) and S3\n",
    "- Spark infrastructure dependence on RAM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444cb95b-a846-4927-8968-abf272004204",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "|![hadoop-emr](../img/hadoop-emr.png)|\n",
    "|:---:|\n",
    "|Instances as a processing cache in an ephemeral Hadoop cluster, Fig 6.7 from Reis (2022). |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f392b421-8679-47a0-9d43-f340368c507c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Hadoop\n",
    "\n",
    "Developed in 2006 to process data with the *MapReduce programming model* (Dean and Ghemawat, 2008), with the \"big data\" processing idea."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26dc7b39-5a95-441b-8748-404b8ae7c668",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Turned into an Apache project in 2008."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ece632-667c-4728-9e4a-4f7090373a57",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Main components of Apache Hadoop:  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d81e333-7281-449a-a637-f8800f637b0c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "- *Hadoop Distributed File System (HDFS)*: Manages large data sets running on commodity hardware (with data replication)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa17ad40-2ef6-42df-a057-4c9ffd407647",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "- Yet Another Resource Negotiator (YARN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deefd6eb-589f-4e78-a6b5-897ec0e907c2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "- *Hadoop MapReduce*: Splits data into blocks, distributes across different nodes, then runs task on each block in parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5821745-45f7-4c6d-8551-e7144bf0e49a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "- Hadoop Common (Hadoop Core): Common libraries and utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8706f99a-44ea-4f9b-8468-40846eff9576",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "*Why Hadoop is not enough?* \n",
    "- Hadoop utilizes external storage.  Read/write latency is high.\n",
    "- All codes must be restricted to a `map` and `reduce` constructs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4945191a-689e-434b-8031-b1912a700ec0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Spark "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103e96b5-9ae8-466c-86c2-d5163276e23d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Spark was originally created at UC Berkeley's AMPLab in 2009 and open-sourced in 2010."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a81a75-86b1-4388-8721-faad5f78ef41",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Spark became an Apache project in 2013."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aead079c-19e7-487d-b4f8-abef7d57b627",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Main components of Apache Spark:  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a13505-ab01-46c3-89dc-614777eadc1d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "- Spark Core: Execution engine for resource coordination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490c4f6c-054a-44a0-94b0-3c1398732376",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "- *Spark SQL*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819620de-cbe1-486a-898f-4f8a4334de80",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "- *Machine Learning Library (MLlib)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc9a8d4-3670-4f20-9183-5f8de2aa4bce",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "- Spark Streaming: Capability for processing streaming data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1c04e4-e0d4-4f9f-81d7-c28066751f58",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "- GraphX: Capability for processing graph-based data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45b5c83-d11b-4bc3-88b9-a590de839fde",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Spark essentially tackles *only* where Hadoop does not perform well, by using an *in-memory* distributed computing engine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1476068f-b8ff-4090-b39f-8dbadd3eed47",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Spark:\n",
    "- makes use of Resilient Distributed Dataset (RDD)\n",
    "- employs dynamic RAM in processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb39f96e-803f-40a3-af5e-85d64ba1b6ee",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Comparison of Hadoop and Spark (*adapted from* AWS summary)\n",
    "\n",
    "|               | Hadoop        |   Spark        |\n",
    "| :-----------: | :-----------: | :------------: |\n",
    "| Architecture     |  stores and processes data on external storage | stores and process data on internal memory |\n",
    "| Performance      | processes data in batches | processes data in real time |\n",
    "| Cost             | *relatively* affordable | comparatively more expensive |\n",
    "| Scalability      | easily scalable | comparatively more challenging |\n",
    "| Machine learning | needs to integrate with external libraries | built-in machine learning libraries |\n",
    "| Security         | strong security features, storage encryption, and access control | basic security |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e08d9d-415b-4995-8ae5-62b7a96a2d2c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## MapReduce (Dean and Ghemawat, 2008)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a686ff43-b789-49cf-a2ae-51ec8c5438df",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "|![mapreduce](../img/mapreduce-trad.jpg)|\n",
    "|:---:|\n",
    "|MapReduce schema from Tian et. al (2015).|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1d6ff7-cfdf-4cb8-b07d-a95e0b300c48",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "## References\n",
    "\n",
    "Reis, J., & Housley, M. (2022). *Fundamentals of data engineering*. O'Reilly Media, Inc.  \n",
    "Dean, J., & Ghemawat, S. (2008). MapReduce: simplified data processing on large clusters. *Communications of the ACM*, 51(1), 107-113.  \n",
    "Tian, W., & Yong, Z. (2015). Energy efficiency scheduling in hadoop, *Optim. Cloud Resour. Manag. Sched*, 179-204."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d42d2fb-c58b-4627-95cb-fec8fc49d6a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
