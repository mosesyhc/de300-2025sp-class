{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32dd3cf7-18cd-45a8-a62c-c814a753b05c",
   "metadata": {},
   "source": [
    "# ðŸ—‚ï¸ MapReduce Tutorial\n",
    "## 1. ðŸ” What is MapReduce?\n",
    "MapReduce is a programming model designed to process large-scale data in a distributed and parallel fashion.\n",
    "\n",
    "It consists of three major phases:\n",
    "\n",
    "- Map: Process input data and output intermediate key-value pairs.\n",
    "\n",
    "- Shuffle/Sort: Group all intermediate values by their key.\n",
    "\n",
    "- Reduce: Aggregate the values associated with each key to produce the final outputâ€‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b06952-0def-41ff-a8c2-fdb067e894ab",
   "metadata": {},
   "source": [
    "## 2. MapReduce Use Case: Word Count\n",
    "### 2.1 Map Phase\n",
    "1. Read input data line by line.\n",
    "2. Tokenize each line into words.\n",
    "3. Emit (word, 1) for each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b239cb-4e51-4ef3-82b5-e32058c9b32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_phase(input_file):\n",
    "    \"\"\"Reads lines from input_file, yields (word, 1) for each word.\"\"\"\n",
    "    with open(input_file, 'r') as f:\n",
    "        for line in f:\n",
    "            words = line.strip().split()\n",
    "            for word in words:\n",
    "                yield (word.lower(), 1)   # Convert to lower case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7e57ef-04a1-4b85-a227-053db1232828",
   "metadata": {},
   "source": [
    "### 2.2 Shuffle/Sort Phase\n",
    "We need to group by the key (the word). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e4acd2-69f3-4713-9fe2-7e74c85ac3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_and_sort(mapped_data):\n",
    "    \"\"\"Groups the mapped data by key (word).\"\"\"\n",
    "    sorted_data = {}\n",
    "    for key, value in mapped_data:\n",
    "        if key not in sorted_data:\n",
    "            sorted_data[key] = []\n",
    "        sorted_data[key].append(value)\n",
    "    return sorted_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0867244-a341-41ff-bd67-b593e8fca84a",
   "metadata": {},
   "source": [
    "### 2.3 Reduce Phase\n",
    "For each word (key), we want to sum up the counts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ac1cae-a003-4c63-858a-77212c034932",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_phase(shuffled_data):\n",
    "    \"\"\"For each word key, sum up all the values.\"\"\"\n",
    "    reduced_data = {}\n",
    "    for key, values in shuffled_data.items():\n",
    "        reduced_data[key] = sum(values)\n",
    "    return reduced_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4745af-1623-4bfa-a14f-62ac6aa9b13e",
   "metadata": {},
   "source": [
    "### 2.4 Putting It All Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff88b289-7ca9-46cc-8590-c3b65a5f799a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Map\n",
    "mapped = map_phase(\"input.txt\")\n",
    "\n",
    "# 2. Shuffle/Sort\n",
    "shuffled = shuffle_and_sort(mapped)\n",
    "\n",
    "# 3. Reduce\n",
    "reduced_result = reduce_phase(shuffled)\n",
    "\n",
    "# Print or save results\n",
    "for word, count in reduced_result.items():\n",
    "    print(f\"{word}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de1ba85-7926-4b45-8ceb-1394ff2ad6ad",
   "metadata": {},
   "source": [
    "## 3. MapReduce Use Case: Calculate Mean and Variance\n",
    "### 3.1 Map Phase: Each input data point emits `(value, valueÂ², count=1)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c97da95-b65a-41fa-afd9-d60123cd6bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_phase(input_file):\n",
    "    \"\"\"Reads numbers from input_file and emits (x, x^2, 1) for each number.\"\"\"\n",
    "    with open(input_file, 'r') as f:\n",
    "        for line in f:\n",
    "            number = float(line.strip())  # Convert string to float\n",
    "            yield (number, number ** 2, 1)  # Emit (x, xÂ², count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f818fc34-8ae0-41d6-aee9-81f6155c817e",
   "metadata": {},
   "source": [
    "### 3.2 Shuffle/Sort: Groups all mapped values together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed95d51d-c8d2-4bc5-858b-5e3f8dfde650",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_and_sort(mapped_data):\n",
    "    \"\"\"Since we are computing global statistics, this simply collects all mapped data.\"\"\"\n",
    "    sum_x = 0\n",
    "    sum_x2 = 0\n",
    "    count = 0\n",
    "    for x, x2, c in mapped_data:\n",
    "        sum_x += x\n",
    "        sum_x2 += x2\n",
    "        count += c\n",
    "    return sum_x, sum_x2, count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0f0122-94fe-4bd1-a45b-ff4efff18d8c",
   "metadata": {},
   "source": [
    "### 3.3 Reduce Step: Compute sum, sum of squares, and count to derive the mean and variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6c05c6-550c-421f-b88d-b16f11b91dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_phase(shuffled_data):\n",
    "    \"\"\"Computes mean and variance from aggregated data.\"\"\"\n",
    "    sum_x, sum_x2, count = shuffled_data\n",
    "    if count == 0:\n",
    "        return None, None  # Avoid division by zero\n",
    "\n",
    "    mean = sum_x / count\n",
    "    variance = (sum_x2 / count) - (mean ** 2)\n",
    "    \n",
    "    return mean, variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c83c4f7-c36f-4a18-a415-50b6817c7bbd",
   "metadata": {},
   "source": [
    "### 3.4 Putting It All Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb39a925-3a28-4e83-8d99-3ad43718bdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Map Phase\n",
    "mapped = map_phase(\"numbers.txt\")  # Input file with numbers\n",
    "\n",
    "# 2. Shuffle & Sort Phase\n",
    "shuffled = shuffle_and_sort(mapped)\n",
    "\n",
    "# 3. Reduce Phase\n",
    "mean, variance = reduce_phase(shuffled)\n",
    "\n",
    "# Print Results\n",
    "print(f\"Mean: {mean}\")\n",
    "print(f\"Variance: {variance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b669d6bb-f6d4-4093-b648-911e0717bd85",
   "metadata": {},
   "source": [
    "## 4. MapReduce Use Case: Linear Regression\n",
    "We want to fit a linear model: $$y = mx + b$$ using gradient descent, which iteratively updates parameters m (slope) and b (intercept) based on the gradient: $$m:= m - \\alpha \\frac{1}{N}\\sum_i((mx_i+b-y_i)x_i)$$\n",
    "where:\n",
    "- $\\alpha$ is the learning rate.\n",
    "- $N$ is the number of data points.\n",
    "\n",
    "### 4.1 Mapper Function\n",
    "Each mapper reads a subset of the data and computes the partial gradients for m and b:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa23162a-2d85-4ff2-a10e-b3624c2f8f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_phase(input_file, m, b):\n",
    "    \"\"\"Computes the partial gradients for m and b for each chunk.\"\"\"\n",
    "    with open(input_file, 'r') as f:\n",
    "        for line in f:\n",
    "            x, y = map(float, line.strip().split(','))  # Read X and Y\n",
    "            error = (m * x + b) - y  # Compute error\n",
    "            gradient_m = error * x   # Partial derivative w.r.t. m\n",
    "            gradient_b = error       # Partial derivative w.r.t. b\n",
    "            yield (1, (gradient_m, gradient_b, 1))  # Emit (key=1, values=(âˆ‚m, âˆ‚b, count=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f42bb9d-21b0-42de-b51d-131acfd42888",
   "metadata": {},
   "source": [
    "### 4.2 Shuffle & Sort Phase\n",
    "This step groups all partial gradients from different mappers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1080be-6053-48f1-ba46-ae9b38fee528",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_and_sort(mapped_data):\n",
    "    \"\"\"Aggregates partial gradients from all mappers.\"\"\"\n",
    "    sum_gradient_m = sum_gradient_b = count = 0\n",
    "    for _, (gradient_m, gradient_b, c) in mapped_data:\n",
    "        sum_gradient_m += gradient_m\n",
    "        sum_gradient_b += gradient_b\n",
    "        count += c\n",
    "    return sum_gradient_m, sum_gradient_b, count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ace3da5-63b3-420e-91c7-bbc56431b11b",
   "metadata": {},
   "source": [
    "### 4.3 Reducer Function\n",
    "The reducer aggregates the gradients and updates m and b:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7836007-cd98-4504-9d8e-f186a9416d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_phase(shuffled_data, m, b, alpha):\n",
    "    \"\"\"Updates m and b using the averaged gradients.\"\"\"\n",
    "    sum_gradient_m, sum_gradient_b, count = shuffled_data\n",
    "    if count == 0:\n",
    "        return m, b  # Avoid division by zero\n",
    "\n",
    "    # Compute the average gradients\n",
    "    avg_gradient_m = sum_gradient_m / count\n",
    "    avg_gradient_b = sum_gradient_b / count\n",
    "\n",
    "    # Update parameters using gradient descent\n",
    "    m -= alpha * avg_gradient_m\n",
    "    b -= alpha * avg_gradient_b\n",
    "\n",
    "    return m, b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee2f58c-fd57-4f62-8218-f4d46b250db9",
   "metadata": {},
   "source": [
    "### 4.4 Put It All Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dc0b1e-485c-4d11-a9d4-7472d47934d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "alpha = 0.1  # Learning rate\n",
    "iterations = 500  # Number of iterations\n",
    "\n",
    "# Initialize parameters\n",
    "m, b = 0.0, 0.0  # Initial guess\n",
    "\n",
    "# Run gradient descent for multiple iterations\n",
    "for i in range(iterations):\n",
    "    print(f\"Iteration {i+1}: m = {m:.4f}, b = {b:.4f}\")\n",
    "\n",
    "    # Step 1: Map (Compute Partial Gradients)\n",
    "    mapped = map_phase(\"data.csv\", m, b)\n",
    "\n",
    "    # Step 2: Shuffle & Sort (Aggregate Gradients)\n",
    "    shuffled = shuffle_and_sort(mapped)\n",
    "\n",
    "    # Step 3: Reduce (Update Parameters)\n",
    "    m, b = reduce_phase(shuffled, m, b, alpha)\n",
    "\n",
    "# Final Model\n",
    "print(f\"Final Linear Regression Model: y = {m:.4f}x + {b:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bf004e-fd4a-4784-91e8-2781ef1282e3",
   "metadata": {},
   "source": [
    "## 5. âœ… Advantages and Limitations\n",
    "âœ… Advantages\n",
    "- Simplifies parallel programming.\n",
    "\n",
    "- Scales horizontally across distributed systems.\n",
    "\n",
    "- Built-in fault tolerance.\n",
    "\n",
    "âŒ Limitations\n",
    "- Poor performance for iterative or real-time algorithms.\n",
    "\n",
    "- Less flexible than general-purpose distributed computing frameworksâ€‹\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da7172a-c93b-4cee-89b3-2e904962679a",
   "metadata": {},
   "source": [
    "## Homework Assignments\n",
    "Please use the same `input.txt` file in section 2, modify mapper/ Reducer function to count all the words with length $>=4$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
